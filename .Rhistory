slice(1:10)
# Create Recipe
rec <- recipe(sales ~ ., data = train) %>%
step_rm(c('store', 'item')) %>%
step_date(date, features = c('doy', 'week', 'month', 'quarter')) %>%
step_mutate_at(all_integer_predictors(), fn = factor) %>%
step_mutate(season = factor(case_when(
between(month(date), 3, 5) ~ "Spring",
between(month(date), 6, 8) ~ "Summer",
between(month(date), 9, 11) ~ "Fall",
TRUE ~ "Winter"
))) %>%
step_mutate(cumulative_sales = cumsum(sales))
# Prep, Bake, and View Recipe
prepped <- prep(rec)
bake(prepped, train) %>%
slice(1:10)
x <- bake(prepped, train) %>%
slice(1:10)
str(x)
# Fit Model
rand_for_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 1000) %>% # Type of Model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
library(vroom)
library(tidyverse)
library(timetk)
library(patchwork)
library(tidyverse)
library(embed)
library(lubridate)
library(rpart)
# Fit Model
rand_for_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 1000) %>% # Type of Model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
library(rpart)
# Fit Model
rand_for_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 1000) %>% # Type of Model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
# Fit Model
rand_for_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 1000,
engine = "ranger",
mode = "regression")
# Fit Model
rand_for_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 1000,
engine = "ranger",
mode = "regression")
# Fit Model
# Fit Model
rand_for_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 1000, # Number of trees in the forest
engine = "ranger", # Specify the R function to use
mode = "regression") # Specify the mode directly
library(parsnip)
library(ranger)
# Fit Model
# Fit Model
rand_for_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 1000, # Number of trees in the forest
engine = "ranger", # Specify the R function to use
mode = "regression") # Specify the mode directly
# Set Workflow
rand_for_workflow <- workflow() %>%
add_recipe(rec) %>%
add_model(rand_for_model)
library(vroom)
library(tidyverse)
library(timetk)
library(patchwork)
library(tidyverse)
library(embed)
library(lubridate)
library(parsnip)
library(ranger)
# Set Workflow
rand_for_workflow <- workflow() %>%
add_recipe(rec) %>%
add_model(rand_for_model)
library(workflows)
# Set Workflow
rand_for_workflow <- workflow() %>%
add_recipe(rec) %>%
add_model(rand_for_model)
# Set Workflow
rand_for_workflow <- workflow() %>%
add_recipe(rec) %>%
add_model(rand_for_model)
tuning_grid <- grid_regular(mtry(range = c(1, 7)), # Grid of values to tune over
min_n(),
levels = 2) # levels = L means L^2 total tuning possibilities
# Packages
library(vroom)
library(tidyverse)
library(timetk)
library(patchwork)
library(tidyverse)
library(embed)
library(lubridate)
library(parsnip)
library(ranger)
library(workflows)
library(tidyverse)
library(vroom)
library(tidymodels)
library(poissonreg)
library(rpart)
library(stacks)
library(dbarts)
library(xgboost)
# Data
train <- vroom("train.csv")
test <- vroom("test.csv")
# Subset store-item combo w my favorite numbers
storeItem <- train %>%
filter(store == 4, item == 17)
# Create Recipe
rec <- recipe(sales ~ ., data = storeItem) %>%
step_rm(c('store', 'item')) %>%
step_date(date, features = c('doy', 'week', 'month', 'quarter')) %>%
step_mutate_at(all_integer_predictors(), fn = factor) %>%
step_mutate(season = factor(case_when(
between(month(date), 3, 5) ~ "Spring",
between(month(date), 6, 8) ~ "Summer",
between(month(date), 9, 11) ~ "Fall",
TRUE ~ "Winter"
))) %>%
step_mutate(cumulative_sales = cumsum(sales)) %>%
step_dummy(all_nominal_predictors()) # Make nominal predictors into dummy variables
# Prep, Bake, and View Recipe
prepped <- prep(rec)
bake(prepped, storeItem)
# Model
plr_model <- linear_reg(penalty = tune(),
mixture = tune()) %>%
set_engine("glmnet") # Function to fit R
# Set Workflow
plr_workflow <- workflow() %>%
add_recipe(rec) %>%
add_model(plr_model)
# Grid of values to tune over
tuning_grid <- grid_regular(penalty(),
mixture(),
levels = 5) # levels = L means L^2 total tuning possibilities
# Split data for CV
folds <- vfold_cv(storeItem,
v = 5, # 5 Folds
repeats = 1)
# Run the CV
cv_results <- plr_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(smape)) # or leave metrics NULL
# Fit Model -------------------------------------
rf_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 500) %>% # Type of Model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
# Workflow w model and recipe -------------------
rf_workflow <- workflow() %>% # Set Workflow
add_recipe(storeItem) %>%
add_model(rf_model)
# Workflow
rf_workflow <- workflow() %>%
add_recipe(rec) %>%
add_model(rf_model)
# Tuning grid
tuning_grid <- grid_regular(mtry(range = c(1, 7)), # Grid of values to tune over
min_n(),
levels = 2) # levels = L means L^2 total tuning possibilities
folds <- vfold_cv(storeItem, # Split data for CV
v = 2, # 2 folds
repeats = 1)
# Run CV
cv_results <- rf_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(smape))
# Find Best Tuning Parameters
bestTune <- cv_results %>%
select_best("smape")
# Create Recipe
rec <- recipe(sales ~ ., data = storeItem) %>%
step_rm(c('store', 'item')) %>%
step_date(date, features = c('week', 'month', 'quarter')) %>%
step_mutate_at(all_integer_predictors(), fn = factor) %>%
step_mutate(season = factor(case_when(
between(month(date), 3, 5) ~ "Spring",
between(month(date), 6, 8) ~ "Summer",
between(month(date), 9, 11) ~ "Fall",
TRUE ~ "Winter"
))) %>%
step_mutate(cumulative_sales = cumsum(sales)) %>%
step_dummy(all_nominal_predictors()) # Make nominal predictors into dummy variables
# Prep, Bake, and View Recipe
prepped <- prep(rec)
bake(prepped, storeItem)
### Model: Random Forest ###
# Model
rf_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 500) %>% # Type of Model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
# Workflow
rf_workflow <- workflow() %>%
add_recipe(rec) %>%
add_model(rf_model)
# Tuning grid
tuning_grid <- grid_regular(mtry(range = c(1, 7)), # Grid of values to tune over
min_n(),
levels = 2) # levels = L means L^2 total tuning possibilities
folds <- vfold_cv(storeItem, # Split data for CV
v = 2, # 2 folds
repeats = 1)
# Run CV
cv_results <- rf_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(smape))
# Find Best Tuning Parameters
bestTune <- cv_results %>%
select_best("smape")
# Find Best Tuning Parameters
bestTune <- cv_results %>%
select_best("smape")
collect_metrics(cv_results) %>%
filter(bestTune) %>%
pull(mean)
# Find Best Tuning Parameters
bestTune <- cv_results %>%
select_best("smape")
collect_metrics(cv_results) %>%
filter(bestTune) %>%
pull(mean)
bestTune
collect_metrics(cv_results) %>%
filter(bestTune)
collect_metrics(cv_results) %>%
filter(bestTune) %>%
pull(mean)
View(cv_results)
View(bestTune)
View(cv_results)
cv_results %>% collect_metrics() %>%
filter(.metrics == "smape")
cv_results %>% collect_metrics() %>%
filter(.metric == "smape")
cv_results %>% collect_metrics() %>%
filter(.metric == "smape") %>%
filter(bestTune)
bestTune
# Find Best Tuning Parameters
best_tune <- cv_results %>%
select_best("smape")
cv_results %>% collect_metrics() %>%
filter(.metric == "smape")
best_tune$mtry
cv_results %>% collect_metrics() %>%
filter(.metric == "smape") %>%
filter(.mtry == best_tune$mtry)
cv_results %>% collect_metrics() %>%
filter(.metric == "smape")
cv_results %>% collect_metrics() %>%
filter(.metric == "smape", .mtry == best_tune$mtry)
cv_results %>% collect_metrics() %>%
filter(.metric == "smape")
# Find Best Tuning Parameters
best_tune <- cv_results %>%
select_best("smape")
best_tune
cv_results %>% collect_metrics() %>%
filter(.metric == "smape")
rf_model <- rand_forest(mtry = tune(),
min_n = tune(),
trees = 500) %>% # Type of Model
set_engine("ranger") %>% # What R function to use
set_mode("regression")
# Workflow
rf_workflow <- workflow() %>%
add_recipe(rec) %>%
add_model(rf_model)
# Tuning grid
tuning_grid <- grid_regular(mtry(range = c(1, 7)), # Grid of values to tune over
min_n(),
levels = 5) # levels = L means L^2 total tuning possibilities
folds <- vfold_cv(storeItem, # Split data for CV
v = 5, # 2 folds
repeats = 1)
# Run CV
cv_results <- rf_workflow %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(smape))
# Find Best Tuning Parameters
best_tune <- cv_results %>%
select_best("smape")
best_tune
cv_results %>% collect_metrics() %>%
filter(.metric == "smape")
cv_results %>% collect_metrics() %>%
filter(.metric == "smape") %>%
pull(mean)
# Find Best Tuning Parameters
best_tune <- cv_results %>%
select_best("smape")
best_tune
cv_results %>% collect_metrics() %>%
filter(.metric == "smape")
cv_results %>%
filter(.metric == "smape", mtry == 7, min_n == 2)
View(cv_results)
View(cv_results[[3]][[1]])
cv_results %>% collect_metrics() %>%
filter(.metric == "smape")
install.packages('modeltime')
library(vroom)
library(tidyverse)
library(modeltime)
library(timetk)
# Data
train <- vroom("train.csv")
test <- vroom("test.csv")
# Subset store-item combo w my favorite numbers
storeItem <- train %>%
filter(store == 4, item == 17)
# Treat the problem as if we have 200
# time series (one for each store-item combo)
nStores <- max(train$store)
View(train)
# Subset two store-item combos w my favorite numbers
s4_i17 <- train %>%
filter(store == 4, item == 17)
s6_i13 <- train %>%
filter(store == 6, item == 13)
cv_split_4_17 %>%
tk_time_series_cv_plan() %>% # put into data frame
plot_time_series_cv_plan(date, sales, .interactive = FALSE)
# CV split for 4_17
cv_split_4_17 <- time_series_split(s4_i17,
assess = "3 months",
cumulative = TRUE)
cv_split_4_17 %>%
tk_time_series_cv_plan() %>% # put into data frame
plot_time_series_cv_plan(date, sales, .interactive = FALSE)
# CV for store 4 item 17
cv_split_4_17 <- time_series_split(s4_i17,
assess = "3 months",
cumulative = TRUE)
cv_preds_4_17 <- cv_split_4_17 %>%
tk_time_series_cv_plan() %>% # put into data frame
plot_time_series_cv_plan(date, sales, .interactive = FALSE)
# CV for store 6 item 13
cv_split_6_13 <- time_series_split(s6_i13,
assess = "3 months",
cumulative = TRUE)
cv_split_6_13 %>%
tk_time_series_cv_plan() %>% # put into data frame
plot_time_series_cv_plan(date, sales, .interactive = FALSE)
cv_preds_6_13 <- cv_split_6_13 %>%
tk_time_series_cv_plan() %>% # put into data frame
plot_time_series_cv_plan(date, sales, .interactive = FALSE)
View(train)
es_model_4_17 <- exp_smoothing() %>%
set_engine('ets') %>%
fit(sales~date, data = training(cv_split_4_17))
library(tidymodels)
es_model_4_17 <- exp_smoothing() %>%
set_engine('ets') %>%
fit(sales~date, data = training(cv_split_4_17))
es_model_6_13 <- exp_smoothing() %>%
set_engine('ets') %>%
fit(sales~date, data = training(cv_split_6_13))
s4_i17_test <- test %>%
filter(store == 4, item == 17)
s6_i13_test <- test %>%
filter(store == 6, item == 13)
# Cross-validate to tune model
cv_results_4_17 <- modeltime_calibrate(es_model_4_17,
new_data = s4_i17_test)
# ES for store 6 item 13
es_model_6_13 <- exp_smoothing() %>%
set_engine('ets') %>%
fit(sales~date, data = training(cv_split_6_13))
# Cross-validate to tune model
cv_results_6_13 <- modeltime_calibrate(es_model_4_17,
new_data = s6_i13_test)
# Cross-validate to tune model
cv_results_4_17 <- modeltime_calibrate(es_model_4_17,
new_data = testing(cv_split_4_17))
# Cross-validate to tune model
cv_results_6_13 <- modeltime_calibrate(es_model_4_17,
new_data = testing(cv_split_6_13))
# Visualize CV results
cv_results_4_17 %>%
modeltime_forecast(
new_data = testing(cv_split_4_17),
actual_data = s4_i17
) %>%
plot_modeltime_forecast(.interactive = FALSE)
# Visualize CV results
cv_results_vis_4_17 <- cv_results_4_17 %>%
modeltime_forecast(
new_data = testing(cv_split_4_17),
actual_data = s4_i17
) %>%
plot_modeltime_forecast(.interactive = FALSE)
cv_results_vis_4_17
# ES for store 6 item 13
es_model_6_13 <- exp_smoothing() %>%
set_engine('ets') %>%
fit(sales~date, data = training(cv_split_6_13))
# Cross-validate to tune model
cv_results_6_13 <- modeltime_calibrate(es_model_6_13,
new_data = testing(cv_split_6_13))
# Visualize CV results
cv_results_vis_6_13 <- cv_results_6_13 %>%
modeltime_forecast(
new_data = testing(cv_split_6_13),
actual_data = s6_i13
) %>%
plot_modeltime_forecast(.interactive = FALSE)
cv_results_vis_6_13
cs_results_4_17 %>%
modeltime_refit(data = s4_i17)
cv_results_4_17 %>%
modeltime_refit(data = s4_i17)
# Refit to all data then forecast for store 6 item 13
es_fullfit_6_13 <- cv_results_6_13 %>%
modeltime_refit(data = s6_i13)
es_preds_4_17 <- es_fullfit %>%
modeltime_forecast(h = '3 months') %>%
rename(date = .index, sales = .value)%>%
select(date, sales) %>%
full_join(., y = test, by = "date") %>%
select(id, sales)
es_preds_4_17 <- es_fullfit_4_17 %>%
modeltime_forecast(h = '3 months') %>%
rename(date = .index, sales = .value)%>%
select(date, sales) %>%
full_join(., y = test, by = "date") %>%
select(id, sales)
es_fullfit_4_17 <- cv_results_4_17 %>%
modeltime_refit(data = s4_i17)
es_preds_4_17 <- es_fullfit_4_17 %>%
modeltime_forecast(h = '3 months') %>%
rename(date = .index, sales = .value)%>%
select(date, sales) %>%
full_join(., y = test, by = "date") %>%
select(id, sales)
es_preds_4_17
es_fullfit_plot_4_17 <- es_fullfit_4_17 %>%
modeltime_forecast(h = '3 months', actual_data = s4_i17) %>%
plot_modeltime_forecast(.interactive = FALSE)
es_fullfit_plot_4_17
# Refit to all data then forecast for store 6 item 13
es_fullfit_6_13 <- cv_results_6_13 %>%
modeltime_refit(data = s6_i13)
es_preds_6_13 <- es_fullfit_6_13 %>%
modeltime_forecast(h = '3 months') %>%
rename(date = .index, sales = .value)%>%
select(date, sales) %>%
full_join(., y = test, by = "date") %>%
select(id, sales)
es_fullfit_plot_6_13 <- es_fullfit_6_13 %>%
modeltime_forecast(h = '3 months', actual_data = s6_i13) %>%
plot_modeltime_forecast(.interactive = FALSE)
es_fullfit_plot_6_13
# Plots
pl <- plot_modeltime_forecast()
library(patchwork)
# Four-Way Plot
fourway <- (cv_preds_4_17 + cv_preds_6_13) / (es_fullfit_plot_4_17 + es_fullfit_plot_6_13)
fourway
# Four-Way Plot
fourway <- (cv_results_vis_4_17 + cv_results_vis_6cv_results_vis_4_17_13) / (es_fullfit_plot_4_17 + es_fullfit_plot_6_13)
# Four-Way Plot
fourway <- (cv_results_vis_4_17 + cv_results_vis_6_13) / (es_fullfit_plot_4_17 + es_fullfit_plot_6_13)
fourway
cv_preds_4_17
cv_preds_4_17
# ES for store 4 item 17
es_model_4_17 <- exp_smoothing() %>%
set_engine('ets') %>%
fit(sales~date, data = training(cv_split_4_17))
# Cross-validate to tune model
cv_results_4_17 <- modeltime_calibrate(es_model_4_17,
new_data = testing(cv_split_4_17))
# Visualize CV results
cv_results_vis_4_17 <- cv_results_4_17 %>%
modeltime_forecast(
new_data = testing(cv_split_4_17),
actual_data = s4_i17
) %>%
plot_modeltime_forecast(.interactive = FALSE)
cv_results_vis_4_17
# Plots
plotly::subplot(cv_results_vis_4_17, cv_results_vis_6_13, es_fullfit_plot_4_17, es_fullfit_plot_6_13, nrows = 2)
